
\chapter{Definiciones preliminares} 
\label{chap:definiciones_preliminares}

 En este capítulo se revisarán algunas definiciones de conceptos
 técnicos, para posteriormente utilizarlos sin ambigüedad durante el
 resto de la presentación.

%--------------------------------------------------------------AGENT-%
\section{Agente inteligente}
\label{sec:agente_inteligente}
 
 Un agente es una entidad computacional autónoma, que puede percibir su
 entorno a través de sensores, y actuar en dicho entorno utilizando
 efectores.
 Usualmente, la información que un agente percibe de su entorno es sólo
 parcial.
 Los agentes toman decisiones a partir de la información contenida en
 su base de conocimiento, siguiendo diferentes conjuntos de reglas
 propuestas, y actúan de manera acorde a la decisión tomada.
 Dichas acciones, a su vez, pueden producir efectos en el entorno.
 
 Actualmente los agentes tienen un campo de aplicación muy amplio y
 existen muchos tipos de agentes diferentes (por ejemplo:
 \textit{reactivos}, \textit{deliberativos}, \textit{inteligentes},
 \textit{de interface}, \textit{colaborativos}), los cuales a su vez
 están orientados a distintos entornos de aplicación.
 
 En la mayoría de los casos, los agentes no existen por sí solos, sino
 que participan de un Sistema Multi-Agente (SMA).

%----------------------------------------------------------------MAS-%
\section{Sistema Multi-Agente}
\label{sec:sistema_multiagente}
 
 En un Sistema Multi-Agente (SMA) mas de un agente interactúan para
 lograr un objetivo o realizar una tarea común.
 Cada agente tiene información incompleta y capacidades limitadas, el
 control del sistema es distribuido, los datos están descentralizados,
 y la computación es asincrónica.
 Los agentes se desenvuelven en un entorno dinámico y cambiante, el
 cual no puede predecirse y se ve afectado por las acciones que son
 llevadas a cabo.
 
 Un aspecto importante en SMA es la comunicación entre agentes, la cual
 puede ser necesaria para que los agentes compitan o cooperen de
 acuerdo a sus metas individuales. 
 Los diálogos con otros agentes del mismo ambiente son, actualmente, un
 área de estudio intensivo.

%----------------------------------------------------------------BDI-%
\section{Modelo BDI}
\label{sec:modelo_bdi}
 
 El \textit{modelo Creencia-Deseo-Intención}, en adelante \textit{BDI}
 (\textit{Belief-Desire-Intention}), es un modelo desarrollado para el
 diseño de agentes inteligentes, basado en una vista simplificada de la
 inteligencia humana.
 Como se analizará en la sección \ref{sec:arquitectura_bdi}, el sistema
 presentado en este trabajo implementa una  adaptación de dicho modelo.
 Por esta razón, se introducen en esta sección los  conceptos básicos
 relacionados, que sirvieron de base para nuestro desarrollo.
 
 El modelo BDI está dedicado al modelado formal del razonamiento
 práctico, es  decir, la formalización de las bases y explicaciones
 psicológicas y filosóficas  (provenientes principalmente de la
 filosofía de la mente y de la acción) de los  conceptos de agente,
 acción, intención, creencia, voluntad, deliberación,  razonamiento de
 medios y fines, etc.
 El razonamiento práctico es incorporado  en agentes (por ejemplo, los
 seres humanos) capaces de perseguir y, por lo tanto,  comprometerse
 con una determinada meta factible (una acción en particular)  a través
 de una cuidadosa planificación de los medios, de las condiciones
 previas  y las acciones que conducen a ese objetivo.

 Estos conceptos son incorporados al modelo mediante la implementación
 de los  aspectos principales de la teoría del razonamiento práctico
 humano de Michael Bratman (también referido como Belief-Desire-
 Intention, o BDI).
 Es decir, implementa  las nociones de creencia, deseo y (en
 particular) intención, de una manera inspirada  por Bratman.
 Una discusión más extensa puede ser encontrada en el mencionado
 trabajo de Bratman\cite{brat99} y Searle\cite{searle1985}.
 
 Este basamento teórico permite al modelo resolver un problema
 particular que  se presenta en la programación de agentes.
 Provee un mecanismo para separar la  actividad de seleccionar un plan
 de la ejecución de los planes actualmente activos.
 Los agentes BDI son capaces de balancear el tiempo invertido en
 deliberar sobre los planes (elegir qué hacer) y ejecutar estos planes
 (llevarlo a cabo).
 La actividad  de crear los planes en primera instancia, escapa al
 alcance del modelo.

\subsection{Creencias, Deseos e Intenciones}
\label{sub:creencia_deseos_intenciones}
 
 Las \textit{creencias, deseos e intenciones} son consideradas estados
 mentales  intencionales (de forma opuesta a, por ejemplo, el dolor o
 el placer).
 Las \textit{creencias}  describen la percepción de la realidad a
 través de datos provenientes de  los sentidos.
 Representan el estado \textit{informacional} del agente; comprenden el
 conocimiento (tanto de sentido común como teórico) sobre el mundo, ya
 sea  externo o interno.
 Están sujetas a revisión, lo que implica que pueden  cambiar en el
 futuro, pueden ser rechazadas o agregadas.
 
 Los \textit{deseos} e \textit{intenciones}, pueden ser vistos como
 conceptos que  se asemejan, aunque con algunas sutiles diferencias.
 Los deseos representan el  estado \textit{motivacional} del agente;
 consisten en su voluntad de alcanzar  ciertos objetivos o situaciones.
 Entre los deseos, se distingue la noción de  \textit{meta}.
 Una meta es un deseo que ha sido adoptado por el agente para  ser
 perseguido activamente.
 Esta definición impone la restricción de que el  conjunto de metas, o
 deseos activos, debe ser consistente.
 
 Por último, el concepto de intención representa el estado
 \textit{deliberativo} del agente, lo que el agente ha elegido hacer.
 Constituyen deseos para los cuales el agente se ha comprometido.
 Es una noción más ligado al compromiso que es  asumido, en función
 alcanzar los estados o situaciones deseadas.

\subsection{Deliberación y planificación}
\label{sub:deliberacion_planificacion}
 
 Por \textit{deliberación} entendemos lo que la literatura denomina
 \textit{silogismo práctico}, es decir, la inferencia de una intención
 a partir de un conjunto de creencias y deseos.
 Esto es, la selección de un deseo factible.
 Una \textit{decisión}  consiste en el último paso de este proceso de
 inferencia mediante el cual  resulta electo uno de muchos deseos y
 potenciales intenciones.
 Es, por esto, un concepto ligado directamente al de intención.
 Definir una intención implica, en  términos de agentes implementados,
 comenzar la ejecución de un \textit{plan}.
 
 Una \textit{acción} puede ser definida, intuitivamente, como la
 ejecución de una operación que causa un determinado efecto o
 consecuencia sobre el entorno en el cual se está desempeñando el
 agente.
 La \textit{planificación} consiste  en la disposición de una secuencia
 de acciones con el fin de lograr una (o más) de sus intenciones de
 alcanzar una meta.
 Los planes pueden ser complejos en mayor o menor medida, en función a
 la cantidad de acciones que contiene.
 En  particular, los planes pueden contener otros planes, dado que
 satisfacer una meta puede requerir la satisfacción de metas
 intermedias.
 Esto refleja que en  el modelo de Bratman, inicialmente los planes son
 concebidos sólo parcialmente,  y los detalles son incorporados a
 medida que progresa su ejecución.

%---------------------------------------------------------------DELP-%
\section{Programación Lógica Rebatible}
\label{sec:programacion_logica_rebatible}
 
 A continuación introducimos las definiciones básicas necesarias para
 representar conocimiento en Programación Lógica Rebatible (\DLP). Para
 un tratamiento exhaustivo, se remite al lector interesado al trabajo
 de A. García y G. Simari\cite{delp04}.  En lo que sigue, se asume que
 el lector posee un conocimiento básico acerca de los aspectos
 fundamentales de la programación lógica.

 \begin{definicion}(Programa \DLP\ \PP)
 \label{def:programa_delp}
 
 Un programa lógico rebatible (delp) es un conjunto \PP\ = \SD\ donde
 \SSet\ y \DD\ representan conjuntos de conocimiento \textit{estricto}
 y \textit{rebatible}, respectivamente. El conjunto \SSet\ de
 conocimiento estricto involucra \textit{reglas estrictas} de la forma
 \srule{L}{Q_1,\ldots,Q_k} y \textit{hechos} (reglas estrictas con
 cuerpo vacío), y se asume que es \textit{no-contradictorio}.  El
 conjunto \DD\ de conocimiento rebatible involucra \textit{reglas
 rebatibles} de la forma  \drule{L}{Q_1,\ldots,Q_k}, lo cual se
 interpreta como ``$Q_1,\ldots,Q_k$ proveen razones tentativas  para
 creer $L$''. Las reglas estrictas y rebatibles en \DLP\ son definidas
 usando un conjunto  finito de literales. Un literal es un átomo ($L$),
 la negación estricta de un átomo ($\sim L$) o  la negación
 \textit{default} de un átomo (\textit{not} $L$).
 
 \end{definicion}
 
 El lenguaje lógico subyacente en \DLP\ es el de la programación lógica
 extendida, enriquecido con el símbolo especial ``\drule{}{}'' para
 denotar reglas rebatibles. Tanto la negación  \textit{default} como la
 clásica están permitidas (denotadas \textit{not} y \textit{$\sim$},
 respectivamente). Sintácticamente, el símbolo ``\drule{}{}'' es lo
 único que distingue un regla \textit{rebatible}
 \drule{L}{Q_1,\ldots,Q_k} de una regla \textit{estricta} (no-
 rebatible) \srule{L}{Q_1,\ldots,Q_k}.  Las reglas \DLP\, por lo tanto,
 son consideradas como \textit{reglas de inferencia} en lugar
 implicaciones. De forma análoga a la programación lógica tradicional,
 la \textit{definición} de un predicado $P$ en \PP , denotado
 $P^{\scriptsize{\PP}}$, está dada por el conjunto de todas las reglas
 (estrictas y rebatibles) con cabeza $P$  y aridad $n$ en \PP . Si $P$
 es un predicado en \PP , entonces \textit{nombre(P)} y
 \textit{aridad(P)} denotan el nombre y la aridad del predicado,
 respectivamente. Escribiremos \textsf{Pred}(\PP) para denotar el
 conjunto de todos los nombres de predicados definidos en un programa
 \DLP\ \PP.

\subsection{Argumento, Contraargumento y Derrota}
\label{sub:argumento_contraargumento_derrota}
 
 Dado un programa \DLP\ \PP\ = \SD\, resolver consultas resulta en la
 construcción de \textit{argumentos}. Un argumento \ArgA\ es un
 conjunto (posiblemente vacío) de reglas rebatibles fijas que junto al
 conjunto \SSet\  provee una prueba lógica para un dado literal \ArgQ,
 satisfaciendo los requerimientos adicionales de  \textit{no-
 contradicción} y \textit{minimalidad}. Formalmente:
 
 \begin{definicion}[Argumento]
 \label{def:argumento}
 
 Dado un programa \DLP\ \PP, un argumento \ArgA\ para una consulta
 \ArgQ, notado \AQ\, es un subconjunto de  instancias fijas de las
 reglas rebatibles en \PP, tal que:
    
 \begin{enumerate}[(1)]
 \item existe una derivación rebatible para \ArgQ de \SyA;
 
 \item \SyA\ es no-contradictorio (\ie, \SyA\ no implica dos literales
 complementarios $L$ y \lit{\no L} (o $L$ y \textsf{not}\ $L$), y,
 
 \item \ArgA\ es minimal con respecto al conjunto inclusión (\ie, no
 hay \Ap\ $\subset$ \ArgA\ tal que existe una derivación rebatible para
 \ArgQ\ de \SyAp).
 
 \end{enumerate}
 \end{definicion}

 Un argumento \AaQa\ es un \textit{subargumento} de otro argumento
 \AbQb\ si $\ArgAa \subseteq \ArgAb$. Dado un programa \DLP\ \PP,
 \textit{Args(\PP)} denota el conjunto de todos los posibles argumentos
 que  pueden ser derivados de \PP.

 La noción de derivación rebatible corresponde a la usual derivación
 SLD dirigida por consultas empleada en programación lógica, aplicando
 \textit{backward chaining} a las reglas estrictas y rebatibles; en
 este contexto, un literal negado \lit{\no P} es tratado simplemente
 como un nuevo nombre de predicado \textit{no\_P}. La minimalidad
 impone una especie de ``principio de la navaja de Occam'' sobre la
 construcción  de argumentos. El requerimiento de no-contradicción
 prohíbe el uso de (instancias fijas de) reglas rebatibles en un
 argumento \ArgA\ cuando \SyA\ deriva dos literales complementarios. Es
 de notar que el concepto de no-contradicción captura los dos enfoques
 usuales de negación en la programación lógica (negación
 \textit{default} y negación clásica), ambas presentes en \DLP\ y
 relacionadas a la noción de contraargumento, como se muestra a
 continuación.
 
 \begin{definicion}[\textbf{Contraargumento}]
 \label{def:contraargumento}
 
 Un argumento \AaQa\ es un \textit{contraargumento} para un argumento
 \AbQb\ si y sólo si
 
 \begin{enumerate}[a)]
 
 \item (ataque a subargumento) existe un subargumento \AQ\ de \AbQb\ 
 (llamado \textit{subargumento en desacuerdo}) tal que el conjunto 
 \SyQaQ\ es contradictorio, o
 
 \item (ataque por negación default) un literal \negda{\ArgQa}\ está
 presente en el cuerpo de alguna  regla en \ArgAb.
 
 \end{enumerate}  
 \end{definicion}
 
 La primer noción de ataque es tomada del framework de Simari-Loui; la
 última está relacionada al  enfoque argumentativo de programación
 lógica de Dung, asi como también a otras formalizaciones, como el
 trabajo de Prakken y Sartor, o el trabajo de Kowa y Toni.
 
 Como en muchos marcos de argumentación, vamos a asumir un
 \textit{criterio de preferencia} para los  argumentos en conflicto
 definido como la relación $\preceq$, la cual es un subconjunto del
 producto  cartesiano \textit{Args(\PP)} $\times$ \textit{Args(\PP)}.
 Esto lleva a la noción de \textit{derrota} entre argumentos como una
 refinación del criterio de contraargumento. En particular, vamos a
 distinguir entre  dos tipos de derrotadores, \textit{propios} y
 \textit{por bloqueo}.
 
 \begin{definicion}[\textbf{Derrotadores propios y por bloqueo}]
 \label{def:derrotadores}
 
 Un argumento \AaQa\ es un \textit{derrotador propio} para un argumento
 \AbQb\ si \AaQa\ contra-argumenta \AbQb\ con un sub-argumento en
 desacuerdo \AQ\ (ataque a subargumento) y \AaQa\ es estrictamente
 preferido sobre \AQ\ con respecto a $\preceq$.
 
 Un argumento \AaQa\ es un \textit{derrotador por bloqueo} para un
 argumento \AbQb\ si \AaQa\ contra-argumenta \AbQb\ y una de las
 siguientes situaciones se presenta: (a) Hay un sub-argumento en
 desacuerdo \AQ\ para \AbQb, y \AaQa\ y \AQ\ no están relacionados
 entre sí con respecto a $\preceq$; o (b) \AaQa\ es un ataque  por
 negación default sobre algún literal \negda{\ArgQa}\ en \AbQb.
 
 El término \textit{derrotador} será usado para referirse
 indistintamente a derrotadores propios o por bloqueo.
 \end{definicion}
 
 La especificidad generalizada es típicamente usada como un criterio de
 preferencia basado en la sintaxis  para argumentos en conflicto,
 favoreciendo aquellos argumentos que están \textit{más informados} o
 son  \textit{más directos}. A modo de ejemplo, consideremos tres
 argumentos 

 \nlA{
   \AS{\drule{a}{b,c}}{a}, \AS{\drule{\no $a$}{b}}{\no a} y \AS{(\drule{a}{b});(\drule{b}{c})}{a}
 }

 \noindent
 construidos sobre la base de un programa 

 \nlA{
   \PP\ = \SD\ = ($\{b,c\},\{\drule{b}{c};\drule{a}{b};\drule{a}{b,c};\drule{\no a}{b}\}$).
 }

 Si se utiliza especificidad generalizada como criterio de
 comparación entre argumentos, el argumento  \AS{\drule{a}{b,c}}{a}
 sería preferido sobre el argumento \AS{\drule{\no $a$}{b}}{\no a} ya
 que el primero es considerado \textit{más informado} (\ie, está basado
 en más premisas). Sin embargo, el argumento  \AS{\drule{\no
 $a$}{b}}{\no a} es preferido sobre \AS{(\drule{a}{b});(\drule{b}{c})}{a} 
 ya que el primero es considerado
 \textit{más directo} (\ie, es obtenido a partir de una derivación más
 corta). Sin embargo, debe ser remarcado que, además de especificidad,
 otros criterios de preferencia alternativos pueden ser usados;  \eg,
 aplicar prioridad sobre las reglas para definir la comparación de
 argumentos, o considerar valores  numéricos correspondientes a medidas
 asociadas a conclusiones de argumentos. El primer enfoque es empleado
 en {\footnotesize D}-P{\footnotesize ROLOG}, Lógica Rebatible,
 extensiones de la Lógica Rebatible, y programación lógica sin negación
 por falla. El segundo criterio fue el aplicado en el desarrollo del
 sistema que se presenta en los capítulos siguientes.

\subsection{Cómputo de garantías a través de análisis dialéctico}
\label{sub:computo_garantias}
 
 Dado un argumento \AQ, pueden existir diferentes derrotadores $\BaQa$
 $\ldots$ $\BkQk$, k $\ge$ 0 para \AQ. Si el argumento \AQ\ es
 derrotado, entonces ya no estaría soportando su conclusión \ArgQ.  Sin
 embargo, dado que los derrotadores son argumentos, estos pueden a su
 vez ser derrotados. Esto  induce un análisis dialéctico recursivo
 completo para determinar qué argumentos son derrotados en  última
 instancia. Para caracterizar este proceso, primero se introducen
 algunas nociones auxiliares.
 
 Una \textit{línea argumentativa} comenzando en un argumento \AoQo\
 (denotado $\lambda^{\scriptsize \AoQo}$) es una secuencia [\AoQo,
 \AaQa, \AbQb,\ldots,\AnQn\ldots] que puede ser pensada como un
 intercambio de  argumentos entre dos partes, un \textit{proponente}
 (argumentos en posiciones pares) y un \textit{oponente} (argumentos en
 posiciones impares). Cada \AiQi\ es un derrotador para el argumento
 previo \AimQim\ en la secuencia, $i > 0$.
 
 A fin de evitar razonamiento \textit{falaz} o mal-formado (\eg ,
 lineas argumentativas infinitas), el  análisis dialéctico impone
 restricciones adicionales para que el intercambio de argumentos pueda
 ser  considerado racionalmente \textit{aceptable}. Puede ser probado
 que las líneas argumentativas aceptables  son finitas. Un tratamiento
 exhaustivo sobre restricciones de aceptabilidad pueden ser encontradas
 en el trabajo de García y Simari\cite{delp04}.
 
 Dado un programa \DLP\ \PP\ y un argumento inicial \AoQo, el conjunto
 de todas las líneas argumentativas aceptables comenzando en \AoQo\ da
 lugar a un análisis dialéctico completo para \AoQo\ (\ie, todos los
 diálogos posibles sobre \AoQo\ entre proponente y oponente),
 formalizado mediante un \textit{árbol dialéctico}.
 
 Los nodos en un árbol dialéctico $T_{\scriptsize \AoQo}$ pueden ser
 marcados como nodos \textit{derrotados}  y \textit{no derrotados}
 (nodos D -\textit{defeated}- y nodos U -\textit{undefeated}-,
 respectivamente).  Un árbol dialéctico será marcado como un árbol
 {\footnotesize AND-OR}: todas las hojas en  $T_{\scriptsize \AoQo}$
 serán marcadas como nodos U (dado que no poseen derrotadores), y cada
 nodo interno  será marcado como nodo D si y sólo si tiene al menos un
 nodo U como hijo, y como nodo U en otro caso.  Un argumento \AoQo\ es
 finalmente aceptado como válido (o \textit{garantizado}) con respecto
 a un programa  \DLP\ \PP\  si y sólo si la raíz del árbol dialéctico
 asociado $T_{\scriptsize \AoQo}$ está etiquetado como \textit{nodo U}.
 
 Dado un programa \DLP\ \PP, resolver una consulta \ArgQ\ con respecto
 a \PP\ implica determinar si \ArgQ\ está soportado por (al menos) un
 argumento garantizado. Diferentes actitudes doxásticas %? pueden ser
 distinguidas de la siguiente manera:
 
 \begin{enumerate}[(1)]
 
 \item textit{Yes}: se cree ArgQ si y sólo si hay al menos un argumento
 garantizado soportando ArgQ en base a PP.
 
 \item \textit{No}: se cree \lit{\no \ArgQ} si y sólo si hay al menos
 un argumento garantizado  soportando \lit{\no \ArgQ} en base a \PP.
 
 \item textit{Undecided}: ni ArgQ ni lit{no ArgQ} están garantizados
 con respecto a PP.
 
 \item textit{Unknown}: ArgQ no se encuentra en el lenguaje de PP.
 
 \end{enumerate}

%---------------------------------------------------------------MAPC-%
\section{Multi-Agent Programming Contest}
\label{sec:mapc}

 El \textit{Multi-Agent Programming Contest} es un concurso de
 programación de Inteligencia Artificial iniciado en el año 2005 con el
 objetivo de estimular la investigación en el área de desarrollo y
 programación de Sistemas Multi-Agente.
 Para ello, la competencia propone diferentes escenarios de juego de
 manera anual, que obligan a los participantes tanto a identificar y
 resolver problemas clave, como a explorar lenguajes, plataformas y
 herramientas de programación para Sistemas Multi-Agente.

\subsection{Escenario MAPC 2011}
\label{sub:escenario_mapc}

 El escenario del año 2011 está formado por el mapa de un planeta
 representado mediante un grafo.
 Cada nodo del grafo es una locación válida (y tiene un valor
 determinado), y existen arcos (con diferente costo de energía) que
 permiten a un agente desplazarse de una locación a otra.
 
 En cada ronda de la competición participan dos equipos rivales.
 Cada equipo posee un conjunto de agentes con diferentes roles
 preestablecidos (\textit{Explorador}, \textit{Saboteador},
 \textit{Reparador}, \textit{Sentinela} e \textit{Inspector}).
 El rol de cada agente define tanto el conjunto de acciones que puede
 realizar, como sus características físicas (\textit{Energía},
 \textit{Salud}, \textit{Fuerza} y \textit{Rango de Visión}).

\subsubsection{Puntaje}
\label{subsub:puntaje}

 La simulación del juego se desarrolla por pasos, y en cada paso se
 otorga a los equipos una determinada cantidad de puntos según el
 estado de la simulación.
 El objetivo del juego es obtener la mayor cantidad de puntos posibles
 cuando la simulación termina.
 
 Para obtener puntos, los agentes de cada uno de los equipos deben
 lograr formar \textit{"`zonas"'} en el mapa logrando posicionarse en
 diferentes locaciones de manera estratégica. 
 
 La predominancia de un equipo sobre el otro en los nodos es
 determinada por un algoritmo bien definido para la competencia, y el
 valor de todos los nodos dominados por un equipo es el principal
 factor del puntaje otorgado en cada uno de los pasos de la simulación.
 
 Algunas otras situaciones, como el logro de determinados
 \textit{achievements}, pueden otorgar puntos adicionales y dinero al
 equipo.

\subsubsection{Acciones}
\label{subsub:acciones}

 Todos los agentes tienen acciones en común que pueden realizar en cada
 uno de los pasos de la simulación:
 
 \begin{itemize}
 
 \item goto(X): el agente se desplaza hacia el nodo X, siempre y cuando
 exista un arco que conecte el nodo actual del agente con X, y dicho
 arco tenga un costo menor a la energía actual del agente.
 
 \item survey(X): el agente recibe en su próxima percepción los costos
 de todos los arcos conectados al nodo en el que se encuentra
 actualmente.
 
 \item buy(X): el agente utiliza el dinero obtenido a partir de los
 \textit{achievements} para aumentar el valor máximo de cualquiera de
 sus características físicas (Energía, Salud, Fuerza o Rango de visión)
 en 1 punto.
 
 \item recharge: el agente recupera el 20\% de su energía máxima.
 
 \item skip: el agente pasa al turno siguiente sin realizar ningún tipo
 de acción.
 
 \end{itemize}
 
 Además, según el rol de cada agente, existen algunas acciones
 específicas que pueden realizar:
 
 \begin{itemize}
 
 \item attack(X): acción disponible únicamente para los
 \textit{Saboteadores}; el agente ataca a un enemigo X, si dicho
 enemigo se encuentra en el mismo nodo.
 El ataque, de tener éxito, decrementa la energía del agente enemigo,
 pudiendo deshabilitarlo en caso de que ésta llegue a 0.

 \item parry: acción disponible únicamente para los
 \textit{Reparadores}, textit{Saboteadores} y textit{Sentinelas}.
 La acción protege al agente de los ataques enemigos, impidiendo que
 éstos tengan éxito.
 
 \item probe: acción disponible únicamente para los 
 \textit{Exploradores}.
 El agente recibe en su próxima percepción el valor del nodo en el que
 se encuentra actualmente.
 Ésta acción no sólo resulta importante por conocer el valor del nodo,
 sino que además permite que, cuando el nodo es conquistado por el
 equipo, dicho valor se sume al total de puntos de la zona.
 Un nodo en el que no se realizó \textit{probe} suma únicamente 1 punto
 al valor total de la zona.
 
 \item inspect: acción disponible únicamente para los
 \textit{Inspectores}.
 El inspector recibe en su próxima percepción la información física
 (Salud, Energía, Fuerza, Rango de visión) de todos los agentes
 enemigos que se encuentren en el mismo nodo que él, o en cualquier
 vecino directo.
 
 \item repair(X): acción disponible únicamente para los
 \textit{Reparadores}.
 El reparador aumenta el valor de la Salud actual de su compañero de
 equipo X (volviendo a habilitarlo, en caso de que su Salud fuera 0).
 
 \end{itemize}

